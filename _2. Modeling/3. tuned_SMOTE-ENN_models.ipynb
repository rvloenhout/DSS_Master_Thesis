{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "from functions import rm\n",
    "\n",
    "random_state = 101\n",
    "path_csv = \"/content/drive/MyDrive/Thesis Data/processed_data/Scaled/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "X_train = pd.read_csv(path_csv + \"ontime_reporting_X_train.csv\")\n",
    "y_train = pd.read_csv(path_csv + \"ontime_reporting_y_train.csv\")\n",
    "\n",
    "X_train = rm(X_train)\n",
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Logistic Regression model on SMOTE-ENN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "    params = {\n",
    "        \"C\": trial.suggest_float(\"C\", 0.001, 1000.0, log=True), #log=True helps to search a large range efficiently with fewer trials\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"sag\",\"saga\",\"newton-cholesky\"]), #\"sag\" and \"saga\" works on features with the same scale\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l2\", None])\n",
    "    }\n",
    "\n",
    "    steps = [\n",
    "        (\"smoteenn\", SMOTEENN(random_state=random_state, n_jobs=-1)),\n",
    "        (\"logreg\", LogisticRegression(**params, random_state=random_state, n_jobs=-1, verbose=2))\n",
    "    ]\n",
    "\n",
    "    lr_pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    skfold = StratifiedKFold(n_splits=3, random_state=random_state, shuffle=True)\n",
    "\n",
    "    scores = cross_val_score(lr_pipeline, X_train, y_train, scoring=\"roc_auc\", n_jobs=-1, cv=skfold)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name='Logistic Regression Tuned SMOTE-ENN', sampler=TPESampler(seed=random_state))\n",
    "study.optimize(objective_lr, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.012341115473953784, 'solver': 'saga', 'penalty': None}\n"
     ]
    }
   ],
   "source": [
    "logreg_best_params = study.best_params #\n",
    "print(logreg_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.matplotlib.plot_optimization_history(study) #Optuna trial optimaization history.png\n",
    "visualization.matplotlib.plot_param_importances(study) #Optuna hyperparameter importance.png\n",
    "visualization.plot_slice(study) #Optuna hyperparameter slice plot.png\n",
    "visualization.matplotlib.plot_timeline(study) #Optuna trial timeline.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Tuned models on SMOTE-ENN data/Logistic Regression/Optuna trial optimization history.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(random_state=random_state, n_jobs=-1)\n",
    "X_smoteenn, y_smoteenn = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "tuned_lr_smoteenn = LogisticRegression(**logreg_best_params, random_state=random_state, n_jobs=-1, verbose=2)\n",
    "tuned_lr_smoteenn.fit(X_smoteenn, y_smoteenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study, 'study_logreg_tuned_SMOTE-ENN.pkl')\n",
    "joblib.dump(tuned_lr_smoteenn, 'logreg_tuned_SMOTE-ENN.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned XGBoost model on SMOTE-ENN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/55591063/how-to-perform-smote-with-cross-validation-in-sklearn-in-python\n",
    "\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 150, 350, step=50),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [5e-2, 1e-2, 15e-2, 1e-1, 2e-1]),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.0, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 0, 20),\n",
    "    }\n",
    "\n",
    "    steps = [\n",
    "        (\"smoteenn\", SMOTEENN(random_state=random_state, n_jobs=-1)),\n",
    "        (\"xgb\", xgb.XGBClassifier(**params, random_state=random_state, n_jobs=-1, verbosity=1, device=\"cuda\"))\n",
    "    ]\n",
    "\n",
    "    xgb_pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    skfold = StratifiedKFold(n_splits=3, random_state=random_state, shuffle=True)\n",
    "\n",
    "    scores = cross_val_score(xgb_pipeline, X_train, y_train, cv=skfold, scoring=\"roc_auc\")\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name='XGBoost Tuned SMOTE-ENN', sampler=TPESampler(seed=random_state))\n",
    "study.optimize(objective_xgboost, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_best_params = study.best_params #\n",
    "print(xgboost_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.matplotlib.plot_optimization_history(study) #Optuna trial optimaization history.png\n",
    "visualization.matplotlib.plot_param_importances(study) #Optuna hyperparameter importance.png\n",
    "visualization.plot_slice(study) #Optuna hyperparameter slice plot.png\n",
    "visualization.matplotlib.plot_timeline(study) #Optuna trial timeline.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Tuned models on SMOTE-ENN data/XGBoost/Optuna trial optimization history.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(random_state=random_state)\n",
    "X_smoteenn, y_smoteenn = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "tuned_xgb_smoteenn = xgb.XGBClassifier(**xgboost_best_params, random_state=random_state, n_jobs=-1, verbosity=2, device=\"cuda\")\n",
    "tuned_xgb_smoteenn.fit(X_smoteenn, y_smoteenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study, 'study_XGBoost_tuned_SMOTE-ENN.pkl')\n",
    "joblib.dump(tuned_xgb_smoteenn, 'XGBoost_tuned_SMOTE-ENN.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Random Forests model on SMOTE-ENN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 5, 9),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 150, 350, step=50),\n",
    "    }\n",
    "\n",
    "    steps = [\n",
    "        (\"smotetomek\", SMOTETomek(random_state=random_state, n_jobs=-1)),\n",
    "        (\"rf\", RandomForestClassifier(**params, random_state=random_state, verbose=1, n_jobs=-1))\n",
    "    ]\n",
    "\n",
    "    rf_pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    skfold = StratifiedKFold(n_splits=3, random_state=random_state, shuffle=True)\n",
    "\n",
    "    scores = cross_val_score(rf_pipeline, X_train, y_train, scoring=\"roc_auc\", cv=skfold)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', study_name='Random Forests Tuned SMOTE-Tomek', sampler=TPESampler(seed=random_state))\n",
    "study.optimize(objective_rf, n_trials=20, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_params = study.best_params #\n",
    "print(rf_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.matplotlib.plot_optimization_history(study) #Optuna trial optimaization history.png\n",
    "visualization.matplotlib.plot_param_importances(study) #Optuna hyperparameter importance.png\n",
    "visualization.plot_slice(study) #Optuna hyperparameter slice plot.png\n",
    "visualization.matplotlib.plot_timeline(study) #Optuna trial timeline.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Tuned models on SMOTE-ENN data/Random Forests/Optuna trial optimization history.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(random_state=random_state, n_jobs=-1)\n",
    "X_smoteenn, y_smoteenn = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "tuned_rf_smoteenn = RandomForestClassifier(**rf_best_params, random_state=random_state, verbose=1, n_jobs=-1)\n",
    "tuned_rf_smoteenn.fit(X_smoteenn, y_smoteenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study, 'study_rf_tuned_SMOTE-ENN.pkl')\n",
    "joblib.dump(tuned_rf_smoteenn, 'rf_tuned_SMOTE-ENN.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned TabNet model on SMOTE-ENN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tabnet(trial):\n",
    "\n",
    "    params = {\n",
    "        \"n_d\": trial.suggest_int(\"n_d\", 8,  64, step=4), #limited ram usage\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 2, 10), #limited ram usage\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0, step=0.01),\n",
    "        \"n_shared\": trial.suggest_int(\"n_shared\", 1, 5),\n",
    "        \"lambda_sparse\": trial.suggest_categorical(\"lambda_sparse\", [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]),\n",
    "    }\n",
    "\n",
    "    model_tabnetClass = TabNetClassifier(**params, seed=random_state, verbose=2, optimizer_params=dict(lr=2e-2, weight_decay=1e-5), n_a=params[\"n_d\"], device_name=\"cuda\") #device_name=\"cuda\"\n",
    "\n",
    "    skfold = StratifiedKFold(n_splits=3, random_state=random_state, shuffle=True)\n",
    "\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        smoteenn = SMOTEENN(random_state=random_state, n_jobs=-1)\n",
    "        X_smoteenn, y_smoteenn = smoteenn.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "        model_tabnetClass.fit(X_train = X_smoteenn.values,\n",
    "                              y_train = y_smoteenn,\n",
    "                              eval_set = [(X_val_fold.values, y_val_fold)],\n",
    "                              patience=2,\n",
    "                              max_epochs=4,\n",
    "                              batch_size=14000,\n",
    "                              virtual_batch_size=14000,\n",
    "                              eval_metric=[\"auc\"]\n",
    "                              )\n",
    "\n",
    "        y_pred = model_tabnetClass.predict_proba(X_val_fold.values)\n",
    "\n",
    "        auc_scores.append(roc_auc_score(y_val_fold, y_pred[:,1]))\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet Tuned SMOTE-ENN', sampler=TPESampler(seed=random_state))\n",
    "study.optimize(objective_tabnet, n_trials=20, show_progress_bar=True, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_best_params = study.best_params #\n",
    "print(tabnet_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.matplotlib.plot_optimization_history(study) #Optuna trial optimaization history.png\n",
    "visualization.matplotlib.plot_param_importances(study) #Optuna hyperparameter importance.png\n",
    "visualization.plot_slice(study) #Optuna hyperparameter slice plot.png\n",
    "visualization.matplotlib.plot_timeline(study) #Optuna trial timeline.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/Tuned models on SMOTE-ENN data/TabNet/Optuna trial optimization history.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(random_state=random_state, n_jobs=-1)\n",
    "X_smoteenn, y_smoteenn = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "tabnet_tuned_smoteenn = TabNetClassifier(**tabnet_best_params, seed=random_state, verbose=2, optimizer_params=dict(lr=2e-2, weight_decay=1e-5), n_a=tabnet_best_params[\"n_d\"], device_name=\"cuda\")\n",
    "tabnet_tuned_smoteenn.fit(X_smoteenn.values, y_smoteenn, max_epochs=4, batch_size=44000, virtual_batch_size=44000) #check batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(study, 'study_tabnet_tuned_SMOTE-ENN.pkl')\n",
    "torch.save(tabnet_tuned_smoteenn, 'TabNet_tuned_SMOTE-ENN.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
