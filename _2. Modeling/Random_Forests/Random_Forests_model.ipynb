{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from hyperopt import tpe,hp,Trials\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "random_state = 101\n",
    "path_import_and_export = \"../../../../Thesis_data/processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"MONTH\":\"int64\",\n",
    "    \"DAY_OF_MONTH\":\"int64\",\n",
    "    \"DAY_OF_WEEK\":\"int64\",\n",
    "    \"OP_UNIQUE_CARRIER\":\"object\",\n",
    "    \"TAIL_NUM\":\"object\",\n",
    "    \"ORIGIN_AIRPORT_ID\":\"int64\",\n",
    "    \"ORIGIN\":\"object\",\n",
    "    \"ORIGIN_CITY_NAME\":\"object\",\n",
    "    \"DEST\":\"object\",\n",
    "    \"CRS_DEP_TIME\":\"Int64\",\n",
    "    \"DEP_DEL15\":\"Int64\",\n",
    "    \"DISTANCE_GROUP\":\"int64\",\n",
    "    \"MANUFACTURE_YEAR\":\"Int64\",\n",
    "    \"NUMBER_OF_SEATS\":\"Int64\",\n",
    "    \"AWND\":\"float64\",\n",
    "    \"PRCP\":\"float64\",\n",
    "    \"SNOW\":\"float64\",\n",
    "    \"SNWD\":\"float64\",\n",
    "    \"TMAX\":\"float64\",\n",
    "    \"MEDIAN_AGE\":\"float64\",\n",
    "    \"TOT_POP\":\"Int64\",\n",
    "    \"AVG_HOUSEHOLD_SIZE\":\"float64\", \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime_reporting = pd.read_csv(path_import_and_export + \"ontime_reporting_clean_export.csv\", dtype=dtypes)\n",
    "\n",
    "X = ontime_reporting.loc[:, ontime_reporting.columns != \"DEP_DEL15\"]\n",
    "y = ontime_reporting[\"DEP_DEL15\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catColumns = X_train.select_dtypes(['object']).columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in catColumns:\n",
    "    X_train[col]= le.fit_transform(X_train[col])\n",
    "\n",
    "catColumns = X_test.select_dtypes(['object']).columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in catColumns:\n",
    "    X_test[col]= le.fit_transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rvanl\\Desktop\\DSS_Thesis_Repo\\DSS_Master_Thesis\\_2. Modeling\\Random_Forests\\Random_Forests_model.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/Random_Forests/Random_Forests_model.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m chi2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/Random_Forests/Random_Forests_model.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test \u001b[39m=\u001b[39m SelectKBest(score_func\u001b[39m=\u001b[39mchi2, k\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/Random_Forests/Random_Forests_model.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m fit \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/Random_Forests/Random_Forests_model.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m np\u001b[39m.\u001b[39mset_printoptions(precision\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/Random_Forests/Random_Forests_model.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m sel_filter \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([\u001b[39mlist\u001b[39m(fit\u001b[39m.\u001b[39mscores_)], columns\u001b[39m=\u001b[39montime_reporting\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:472\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    467\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    468\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m], multi_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    469\u001b[0m )\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X, y)\n\u001b[1;32m--> 472\u001b[0m score_func_ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_func(X, y)\n\u001b[0;32m    473\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(score_func_ret, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    474\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscores_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpvalues_ \u001b[39m=\u001b[39m score_func_ret\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:217\u001b[0m, in \u001b[0;36mchi2\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m    215\u001b[0m X \u001b[39m=\u001b[39m check_array(X, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39m(np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32))\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many((X\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(X) \u001b[39melse\u001b[39;00m X) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m--> 217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput X must be non-negative.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    219\u001b[0m \u001b[39m# Use a sparse representation for Y by default to reduce memory usage when\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m# y has many unique classes.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m Y \u001b[39m=\u001b[39m LabelBinarizer(sparse_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mfit_transform(y)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X_train, y_train)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "sel_filter = pd.DataFrame([list(fit.scores_)], columns=ontime_reporting.columns[:-1])\n",
    "sel_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid_rf = {\n",
    "    \"max_depth\": hp.quniform('max_depth',5, 10, 1),\n",
    "    \"max_features\": hp.choice('criterion', ['auto', 'sqrt','log2', None]),\n",
    "    \"n_estimators\": hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "\n",
    "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
    "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])\n",
    "    }\n",
    "\n",
    "def objective(space):\n",
    "    model = RandomForestClassifier(\n",
    "        criterion = space['criterion'], \n",
    "        max_depth = int(space['max_depth']),\n",
    "        max_features = space['max_features'],\n",
    "        min_samples_leaf = space['min_samples_leaf'],\n",
    "        min_samples_split = space['min_samples_split'],\n",
    "        n_estimators = space['n_estimators'], \n",
    "    )\n",
    "    \n",
    "    accuracy = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "\n",
    "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 80,\n",
    "            trials= trials)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=random_state)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid_rf, n_iter = 10, cv = 2, verbose=2, random_state=random_state, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
