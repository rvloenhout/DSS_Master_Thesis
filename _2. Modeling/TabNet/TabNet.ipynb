{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "random_state = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_import_and_export = \"../../../../Thesis_data/processed_data/\"\n",
    "\n",
    "X_train = pd.read_csv(path_import_and_export + \"ontime_reporting_X_train.csv\")\n",
    "y_train = pd.read_csv(path_import_and_export + \"ontime_reporting_y_train.csv\")\n",
    "X_test = pd.read_csv(path_import_and_export + \"ontime_reporting_X_test.csv\")\n",
    "y_test = pd.read_csv(path_import_and_export + \"ontime_reporting_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.ravel(y_train)\n",
    "# np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(X_train)\n",
    "# np.array(y_train)\n",
    "# np.array(X_test)\n",
    "# np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(X_train)\n",
    "# y_train.to_numpy()\n",
    "# X_test.to_numpy()\n",
    "# y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-06 16:05:32,790] A new study created in memory with name: TabNet\n",
      "C:\\Users\\Rvanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.42109 | val_0_auc: 0.7348  |  0:17:43s\n",
      "Stop training because you reached max_epochs = 1 with best_epoch = 0 and best_val_0_auc = 0.7348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rvanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[W 2023-10-06 17:36:56,426] Trial 0 failed with parameters: {'n_d': 8, 'n_steps': 7, 'gamma': 1.6, 'n_shared': 3, 'lambda_sparse': 0.001124255306326657, 'mask_type': 'sparsemax'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Rvanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Rvanl\\AppData\\Local\\Temp\\ipykernel_5540\\1096735439.py\", line 33, in objective_tabnet\n",
      "    model_tabnetClass.fit(X_train = X_train_fold,\n",
      "  File \"C:\\Users\\Rvanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 278, in fit\n",
      "    self.feature_importances_ = self._compute_feature_importances(X_train)\n",
      "  File \"C:\\Users\\Rvanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 759, in _compute_feature_importances\n",
      "    M_explain, _ = self.explain(X, normalize=False)\n",
      "  File \"C:\\Users\\Rvanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 369, in explain\n",
      "    res_masks[key] = np.vstack([res_masks[key], value])\n",
      "  File \"<__array_function__ internals>\", line 180, in vstack\n",
      "  File \"C:\\Users\\Rvanl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\shape_base.py\", line 282, in vstack\n",
      "    return _nx.concatenate(arrs, 0)\n",
      "  File \"<__array_function__ internals>\", line 180, in concatenate\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-06 17:36:56,923] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rvanl\\Desktop\\DSS_Thesis_Repo\\DSS_Master_Thesis\\_2. Modeling\\TabNet\\TabNet.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 51>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity(optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mDEBUG)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m, study_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTabNet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective_tabnet, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    350\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     _optimize(\n\u001b[0;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    452\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\Rvanl\\Desktop\\DSS_Thesis_Repo\\DSS_Master_Thesis\\_2. Modeling\\TabNet\\TabNet.ipynb Cell 7\u001b[0m line \u001b[0;36mobjective_tabnet\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m X_train_fold, X_val_fold \u001b[39m=\u001b[39m X_train[train_index], X_train[val_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m y_train_fold, y_val_fold \u001b[39m=\u001b[39m y_train[train_index], y_train[val_index]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model_tabnetClass\u001b[39m.\u001b[39;49mfit(X_train \u001b[39m=\u001b[39;49m X_train_fold,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                       y_train \u001b[39m=\u001b[39;49m y_train_fold,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                       eval_set \u001b[39m=\u001b[39;49m [(X_val_fold, y_val_fold)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                       patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                       max_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                       batch_size\u001b[39m=\u001b[39;49m\u001b[39m1500\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                       eval_metric\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mauc\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                       )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model_tabnetClass\u001b[39m.\u001b[39mpredict(X_val_fold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X11sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m auc_scores\u001b[39m.\u001b[39mappend(roc_auc_score(y_val_fold, y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py:278\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39meval()\n\u001b[0;32m    276\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_importance:\n\u001b[0;32m    277\u001b[0m     \u001b[39m# compute feature importance once the best model is defined\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_importances_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_feature_importances(X_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py:759\u001b[0m, in \u001b[0;36mTabModel._compute_feature_importances\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compute_feature_importances\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    751\u001b[0m     \u001b[39m\"\"\"Compute global feature importance.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \n\u001b[0;32m    753\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    757\u001b[0m \n\u001b[0;32m    758\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m     M_explain, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplain(X, normalize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    760\u001b[0m     sum_explain \u001b[39m=\u001b[39m M_explain\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    761\u001b[0m     feature_importances_ \u001b[39m=\u001b[39m sum_explain \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(sum_explain)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_tabnet\\abstract_model.py:369\u001b[0m, in \u001b[0;36mTabModel.explain\u001b[1;34m(self, X, normalize)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m         \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m masks\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 369\u001b[0m             res_masks[key] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvstack([res_masks[key], value])\n\u001b[0;32m    371\u001b[0m res_explain \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(res_explain)\n\u001b[0;32m    373\u001b[0m \u001b[39mif\u001b[39;00m normalize:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#https://pypi.org/project/pytorch-tabnet/\n",
    "\n",
    "path_import_and_export = \"../../../../Thesis_data/processed_data/\"\n",
    "\n",
    "X_train = pd.read_csv(path_import_and_export + \"ontime_reporting_X_train.csv\").values.astype(float)\n",
    "y_train = pd.read_csv(path_import_and_export + \"ontime_reporting_y_train.csv\").values\n",
    "X_test = pd.read_csv(path_import_and_export + \"ontime_reporting_X_test.csv\").values.astype(float)\n",
    "y_test = pd.read_csv(path_import_and_export + \"ontime_reporting_y_test.csv\").values\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "def objective_tabnet(trial):\n",
    "\n",
    "    params = {\n",
    "        \"n_d\": trial.suggest_int(\"n_d\", 8,  64, step=4),\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 2.0, step=0.1),\n",
    "        \"n_shared\": trial.suggest_int(\"n_shared\", 1, 5),\n",
    "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 1e-3, 3e-3, log=True),\n",
    "        \"mask_type\": trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    }\n",
    "\n",
    "    model_tabnetClass = TabNetClassifier(**params, seed=random_state, verbose=2, optimizer_params=dict(lr=2e-2, weight_decay=1e-5), n_a=params[\"n_d\"]) #device_name=\"cuda\"\n",
    "\n",
    "    skfold = StratifiedKFold(n_splits=2, random_state=random_state, shuffle=True)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model_tabnetClass.fit(X_train = X_train_fold,\n",
    "                              y_train = y_train_fold,\n",
    "                              eval_set = [(X_val_fold, y_val_fold)],\n",
    "                              patience=5,\n",
    "                              max_epochs=1,\n",
    "                              batch_size=1500,\n",
    "                              eval_metric=[\"auc\"]\n",
    "                              )\n",
    "\n",
    "        y_pred = model_tabnetClass.predict(X_val_fold)\n",
    "\n",
    "        auc_scores.append(roc_auc_score(y_val_fold, y_pred))\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet')\n",
    "study.optimize(objective_tabnet, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_import_and_export = \"../../../../Thesis_data/processed_data/\"\n",
    "\n",
    "X_train = pd.read_csv(path_import_and_export + \"ontime_reporting_X_train.csv\")\n",
    "y_train = pd.read_csv(path_import_and_export + \"ontime_reporting_y_train.csv\", squeeze=True)\n",
    "X_test = pd.read_csv(path_import_and_export + \"ontime_reporting_X_test.csv\")\n",
    "y_test = pd.read_csv(path_import_and_export + \"ontime_reporting_y_test.csv\", squeeze=True)\n",
    "\n",
    "def objective_tabnet(trial):\n",
    "    params = {\n",
    "        \"n_d\": trial.suggest_int(\"n_d\", 8, 16, step=4),\n",
    "        \"n_a\": trial.suggest_int(\"n_a\", 8, 16, step=4),\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
    "        \"cat_emb_dim\": trial.suggest_int(\"cat_emb_dim\", 1, 5),\n",
    "        \"gamma\": trial.suggest_float(\"subsample\", 1.0, 2.0, step=0.01),\n",
    "        \"n_shared\": trial.suggest_int(\"colsample_bytree\", 1, 5),\n",
    "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 1e-3, 3e-3, log=True),\n",
    "        \"mask_type\": trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    }\n",
    "\n",
    "    model_tabnetClass = TabNetClassifier(**params, seed=random_state, verbose=2)\n",
    "\n",
    "    skfold = StratifiedKFold(n_splits=3, random_state=random_state, shuffle=True)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        model_tabnetClass.fit(X_train = X_train_fold.values,\n",
    "                              y_train = y_train_fold.values,\n",
    "                              eval_set = [(X_val_fold.values, y_val_fold.values)],\n",
    "                              patience=5,\n",
    "                              max_epochs=1,\n",
    "                              batch_size=1500,\n",
    "                              eval_metric=[\"auc\"]\n",
    "                              )\n",
    "\n",
    "        y_pred = model_tabnetClass.predict(X_val_fold.values)#[:, 1]\n",
    "        auc_scores.append(roc_auc_score(y_val_fold.values, y_pred))\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet')\n",
    "study.optimize(objective_tabnet, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_tabnet(trial):\n",
    "    params = {\n",
    "        \"n_d\": trial.suggest_int(\"n_d\", 8, 64, step=8),\n",
    "        \"n_a\": trial.suggest_int(\"n_a\", 8, 64, step=8),\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 3, 10),\n",
    "        \"gamma\": trial.suggest_float(\"subsample\", 1.0, 2.0, step=0.01),\n",
    "        \"n_shared\": trial.suggest_int(\"colsample_bytree\", 1, 5)\n",
    "    }\n",
    "\n",
    "    model_tabnetClass = TabNetClassifier(**params, seed=random_state, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits=3, random_state=random_state, shuffle=True)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_val_fold, y_val_fold = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        model_tabnetClass.fit(X_train_fold, y_train_fold,\n",
    "                              eval_set = [(X_val_fold, y_val_fold)],\n",
    "                              patience=5,\n",
    "                              max_epochs=10,\n",
    "                              eval_metric=[\"auc\"])\n",
    "        \n",
    "        y_pred = model_tabnetClass.predict(X_val_fold)#[:, 1]\n",
    "        auc_scores.append(roc_auc_score(y_val_fold, y_pred))\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "study = optuna.create_study(direction=\"maximize\", study_name='TabNet')\n",
    "study.optimize(objective_tabnet, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_d': 8,\n",
       " 'n_a': 16,\n",
       " 'n_steps': 4,\n",
       " 'cat_emb_dim': 2,\n",
       " 'subsample': 1.94,\n",
       " 'colsample_bytree': 3,\n",
       " 'lambda_sparse': 0.0024674522291325534,\n",
       " 'mask_type': 'sparsemax'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TabNet_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TabModel.__init__() got an unexpected keyword argument 'subsample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Rvanl\\Desktop\\DSS_Thesis_Repo\\DSS_Master_Thesis\\_2. Modeling\\TabNet\\TabNet.ipynb Cell 11\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m TabNet_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m final_tabnet_model \u001b[39m=\u001b[39m TabNetClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mTabNet_params, seed\u001b[39m=\u001b[39mrandom_state, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rvanl/Desktop/DSS_Thesis_Repo/DSS_Master_Thesis/_2.%20Modeling/TabNet/TabNet.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m final_tabnet_model\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mTypeError\u001b[0m: TabModel.__init__() got an unexpected keyword argument 'subsample'"
     ]
    }
   ],
   "source": [
    "TabNet_params = study.best_params\n",
    "final_tabnet_model = TabNetClassifier(**TabNet_params, seed=random_state, verbose=1)\n",
    "final_tabnet_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_tabnet_model.predict(X_test)\n",
    "test_auroc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_auroc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
