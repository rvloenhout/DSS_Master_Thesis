{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path_import = \"../../../Thesis_data/raw_data/\"\n",
    "path_export = \"../../../Thesis_data/processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define pre-selected columns from all datasets\n",
    "cols_ontime_reporting = [\"MONTH\", #month of departure, 1 = January, ... 12 = December\n",
    "                         \"DAY_OF_MONTH\", #Day of month of departure\n",
    "                         \"DAY_OF_WEEK\", #Day of week of departure, 1 = Monday, ... 7 = Sunday\n",
    "                         \"TAIL_NUM\", #Unique tail number of aircraft\n",
    "                         \"ORIGIN_AIRPORT_ID\", #Unique airport id, matches with ORIGIN\n",
    "                         \"ORIGIN\", #International Air Transport Association's (IATA) Location Identifier code, unique 3 letter code matches to departure location\n",
    "                         \"ORIGIN_CITY_NAME\", #City name with state abbreviation used to match with us_cities 'City'\n",
    "                         \"DEST\", #International Air Transport Association's (IATA) Location Identifier code, unique 3 letter code matches to destination location\n",
    "                         \"DISTANCE_GROUP\", #Miles between ORIGIN and DESTINATION, grouped together by integers,\n",
    "                         \"CRS_DEP_TIME\", #4 digit military time formatting of the planned departure time\n",
    "                         \"DEP_DEL15\", #Binary number that classifies a delay (1) as: a aircraft departing 15 minutes later than planned\n",
    "                         \"OP_UNIQUE_CARRIER\"\n",
    "                         ]\n",
    "\n",
    "cols_aircraft_inventory = [\"TAIL_NUM\", #Unique tail number of aircraft\n",
    "                           \"MANUFACTURE_YEAR\", #Manufacturing year of the plane\n",
    "                           \"NUMBER_OF_SEATS\" #N of seats on a plane\n",
    "                           ]\n",
    "\n",
    "cols_airport_list = [\"ORIGIN_AIRPORT_ID\", #Unique airport id, matches with ORIGIN_AIRPORT_ID from ontime_reporting\n",
    "                     \"NAME\" #Location of weather reading, matches with NAME from airport_weather\n",
    "                     ]\n",
    "\n",
    "cols_airport_weather = [\"NAME\", #Location of weather reading\n",
    "                        \"DATE\",\n",
    "                        \"PRCP\",\n",
    "                        \"SNOW\",\n",
    "                        \"SNWD\",\n",
    "                        \"TMAX\", #Maximum temperature that day in Fahrenheit\n",
    "                        \"AWND\" #Maximum wind speed that day in Miles per Hour\n",
    "                        ]\n",
    "\n",
    "cols_us_cities = [\"City\",\n",
    "                  \"Median Age\",\n",
    "                  \"Total Population\",\n",
    "                  \"Average Household Size\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading on-time reporting data for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583985, 12)\n",
      "(1117160, 12)\n",
      "(1749234, 12)\n",
      "(2361257, 12)\n",
      "(2997647, 12)\n",
      "(3634338, 12)\n",
      "(4293367, 12)\n",
      "(4951828, 12)\n",
      "(5557807, 12)\n",
      "(6193821, 12)\n",
      "(6796274, 12)\n",
      "(7422037, 12)\n"
     ]
    }
   ],
   "source": [
    "#Loading the ontime_reporting data for each month and concatanating them on an empty DataFrame\n",
    "ontime_reporting_all = pd.DataFrame() #Define empty dataframe\n",
    "\n",
    "#Going through all the CSV files (12, for each month one) related to On-Time Airplane Reporting and concatenating them\n",
    "for i in range(1,13): #13\n",
    "    if i == 1:\n",
    "        ontime_reporting_montly = pd.read_csv(path_import + \"ONTIME_REPORTING_\" + str(i) + \".csv\", usecols=cols_ontime_reporting)\n",
    "        ontime_reporting_all = ontime_reporting_montly\n",
    "        print(ontime_reporting_all.shape)\n",
    "    else:\n",
    "        ontime_reporting_montly = pd.read_csv(path_import + \"ONTIME_REPORTING_\" + str(i) + \".csv\", usecols=cols_ontime_reporting)\n",
    "        ontime_reporting_all = pd.concat([ontime_reporting_all, ontime_reporting_montly])\n",
    "        print(ontime_reporting_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading aircraft inventory data and merging with on-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of aircraft_inventory_data:  (7383, 3)\n",
      "Shape of ontime_reporting_all before merge:  (7422037, 12)\n",
      "Shape of ontime_reporting_all after merge:  (7441892, 14)\n"
     ]
    }
   ],
   "source": [
    "#Loading aircraft inventory list and merging it with ontime_reporting_all\n",
    "aircraft_inventory_data = pd.read_csv(path_import + \"B43_AIRCRAFT_INVENTORY.csv\", encoding='latin1', usecols=cols_aircraft_inventory)\n",
    "print(\"Shape of aircraft_inventory_data: \", aircraft_inventory_data.shape)\n",
    "print(\"Shape of ontime_reporting_all before merge: \", ontime_reporting_all.shape)\n",
    "ontime_reporting_all = ontime_reporting_all.merge(aircraft_inventory_data, on='TAIL_NUM', how=\"left\")\n",
    "print(\"Shape of ontime_reporting_all after merge: \", ontime_reporting_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading airport and weather data then merging them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of airport_list_data:  (97, 2)\n",
      "Shape of airport_weather_data:  (38675, 7)\n"
     ]
    }
   ],
   "source": [
    "#Loading airport_list and airport_weather and meging it with ontime_reporting_all\n",
    "airport_list_data = pd.read_csv(path_import + \"airports_list.csv\", usecols=cols_airport_list)\n",
    "print(\"Shape of airport_list_data: \", airport_list_data.shape)\n",
    "airport_weather_data = pd.read_csv(path_import + \"airport_weather_2019.csv\", usecols=cols_airport_weather)\n",
    "print(\"Shape of airport_weather_data: \", airport_weather_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting DATE to datetime dtype and extracting Month and Day for merging with ontime_reporting_all\n",
    "airport_weather_data['DATE'] = pd.to_datetime(airport_weather_data['DATE'])\n",
    "airport_weather_data['MONTH'] = pd.DatetimeIndex(airport_weather_data['DATE']).month\n",
    "airport_weather_data['DAY_OF_MONTH'] = pd.DatetimeIndex(airport_weather_data['DATE']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of airport_weather_data before merge:  (38675, 9)\n",
      "Shape of airport_weather_data after merge:  (35025, 10)\n"
     ]
    }
   ],
   "source": [
    "#Merging airport_list with airport_weather for linking ORIGIN_AIRPORT_ID to NAME\n",
    "#An left join was made because if an inner join would have been made we would have lost relevant weather data\n",
    "print(\"Shape of airport_weather_data before merge: \", airport_weather_data.shape)\n",
    "airport_weather_data = airport_list_data.merge(airport_weather_data, on=\"NAME\", how=\"left\")\n",
    "print(\"Shape of airport_weather_data after merge: \", airport_weather_data.shape)\n",
    "\n",
    "#Dropping redundant columns\n",
    "airport_weather_data = airport_weather_data.drop(columns=[\"NAME\", \"DATE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Weather and on-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ontime_reporting_all before merge:  (7441892, 14)\n",
      "Shape of ontime_reporting_all after merge:  (6708260, 19)\n"
     ]
    }
   ],
   "source": [
    "#Merging airport_weather_data with ontime_reporting_all\n",
    "#An inner join has been chosen here because when weather was missing it was almost completly missing from \n",
    "print(\"Shape of ontime_reporting_all before merge: \", ontime_reporting_all.shape)\n",
    "ontime_reporting_all = ontime_reporting_all.merge(airport_weather_data, how='inner', on=['ORIGIN_AIRPORT_ID', 'MONTH', 'DAY_OF_MONTH'])\n",
    "print(\"Shape of ontime_reporting_all after merge: \", ontime_reporting_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and merging US city and on-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of us_cities_data:  (2891, 4)\n"
     ]
    }
   ],
   "source": [
    "#Loading US Cities data using predefined columns\n",
    "us_cities_data = pd.read_csv(path_import + \"us-cities-demographics-2015.csv\", usecols=cols_us_cities, delimiter=\";\")\n",
    "print(\"Shape of us_cities_data: \", us_cities_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining US cities column names to match City with ORIGIN_CITY_NAME from on-time reporting data\n",
    "us_cities_data.rename(columns = {\"City\":\"ORIGIN_CITY_NAME\", \"Median Age\":\"MEDIAN_AGE\", \"Total Population\":\"TOT_POP\", \"Average Household Size\":\"AVG_HOUSEHOLD_SIZE\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of us_cities_data:  (567, 4)\n"
     ]
    }
   ],
   "source": [
    "#Removing duplicates as the demograhics are devided into race with a seperate count but general statistics are the same but just repeating per city\n",
    "us_cities_data = us_cities_data.drop_duplicates(subset='ORIGIN_CITY_NAME')\n",
    "print(\"Shape of us_cities_data: \", us_cities_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting City name and state from on-time reporting data and dropping state abbreviation\n",
    "ontime_reporting_all[\"ORIGIN_CITY_NAME\"] = ontime_reporting_all['ORIGIN_CITY_NAME'].str.split(',').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of ontime_reporting_all before merge:  (6708260, 19)\n",
      "Shape of ontime_reporting_all before merge:  (6001976, 22)\n"
     ]
    }
   ],
   "source": [
    "#Merging on-time reporting with US cities data via an inner join,\n",
    "#The inner join has been chosen because it is difficult to impute the missing values for each city when doing a left join and would only generate noise and a skewed image\n",
    "print(\"Shape of ontime_reporting_all before merge: \", ontime_reporting_all.shape)\n",
    "ontime_reporting_all = ontime_reporting_all.merge(us_cities_data, how='inner', on='ORIGIN_CITY_NAME')\n",
    "print(\"Shape of ontime_reporting_all before merge: \", ontime_reporting_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the whole dataset\n",
    "ontime_reporting_all.to_csv(path_export + \"ontime_reporting_export.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
